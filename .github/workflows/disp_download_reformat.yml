# DISP subset + reformat, on demand
name: disp_download_reformat
run-name: ${{ inputs.workflow_name }}

on:
  workflow_dispatch:
    inputs:
      frame_id:
        type: string
        description: Sentinel-1 frame ID
        required: true
        default: '20697'
      output_name:
        type: string
        description: Output file name. Must end in .zarr (for Zarr output), .nc (for NetCDF output)
        required: false
        default: 'disp-output.zarr'
      bbox:
        type: string
        description: >-
          Bounding box as "minlon minlat maxlon maxlat"
        required: true
        default: '-102.71 31.35 -102.6 31.45'
      reference_method:
        type: string
        description: Method of spatially referencing each epoch (HIGH_COHERENCE,BORDER,MEDIAN)
        required: true
        default: 'BORDER'
      start_datetime:
        type: string
        description: Start date (YYYY-MM-DD)
        required: true
        default: '2021-01-01'
      end_datetime:
        type: string
        description: End date (YYYY-MM-DD)
        required: true
        default: '2024-01-01'
      num_workers:
        type: number
        description: Parallel download workers
        required: false
        default: 4
      workflow_name:
        type: string
        description: Custom run name
        required: false
        default: 'disp_download_reformat'

jobs:
  disp_download_reformat:
    name: ${{ inputs.workflow_name }}
    runs-on: ubuntu-latest
    defaults:
      run:
        shell: bash -el {0}

    steps:
      # Checkout repo (needed for pixi.toml and/or local packages)
      - name: Checkout repository
        uses: actions/checkout@v4

      # Earthdata credentials (if your commands hit NASA HTTPS)
      - name: Configure ~/.netrc for Earthdata
        uses: extractions/netrc@v2
        with:
          machine: urs.earthdata.nasa.gov
          username: ${{ secrets.EARTHDATA_USERNAME }}
          password: ${{ secrets.EARTHDATA_PASSWORD }}

      - name: Setup environment
        uses: mamba-org/setup-micromamba@v2
        with:
          environment-file: environment.yml
          environment-name: opera_utils-env
          generate-run-shell: false
          condarc: |
            channels:
              - conda-forge
      - name: Install
        run: |
          pip install .[disp]

      # Run the two DISP commands and zip the result
      - name: Download and reformat DISP subset
        run: |
          set -eo pipefail
          export NUM_WORKERS=${{ inputs.num_workers }}

          echo "Downloading NetCDF subset..."
          opera-utils disp-s1-download \
            --output-dir subset-ncs \
            --bbox ${{ inputs.bbox }} \
            --frame-id ${{ inputs.frame_id }} \
            --start-datetime ${{ inputs.start_datetime }} \
            --end-datetime ${{ inputs.end_datetime }} \
            --num-workers $NUM_WORKERS

          echo "Reformatting to ${{ inputs.output_name }}"
          opera-utils disp-s1-reformat \
            --reference-method ${{ inputs.reference_method }} \
            --output-name ${{ inputs.output_name }} \
            --input-files subset-ncs/OPERA_L3_DISP-S1*.nc

          # Check if output_name ends with .nc and zip only in that case
          if [[ "${{ inputs.output_name }}" == *.nc ]]; then
            echo "Zipping product..."
            zip -1 -r ${{ inputs.output_name }}.zip ${{ inputs.output_name }} subset-ncs/
            # Set artifact path for the upload step
            echo "ARTIFACT_PATH=${{ inputs.output_name }}.zip" >> $GITHUB_ENV
          else
            # For other formats (like .zarr), just use the output directory
            echo "ARTIFACT_PATH=${{ inputs.output_name }}" >> $GITHUB_ENV
          fi

      # Upload the final artefact (path determined by previous step)
      - name: Upload Result
        uses: actions/upload-artifact@v4
        with:
          name: ${{ inputs.output_name }}
          path: ${{ env.ARTIFACT_PATH }}
          retention-days: 5
